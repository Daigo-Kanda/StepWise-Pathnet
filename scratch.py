import argparse
import datetime
import os
import sys

import tensorflow as tf
from tensorflow import keras

import ITrackerData_Person as data_gen


def main(args):
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        # Restrict TensorFlow to only use the first GPU
        try:
            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')
            logical_gpus = tf.config.experimental.list_logical_devices('GPU')
            print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPU")
        except RuntimeError as e:
            # Visible devices must be set before GPUs have been initialized
            print(e)

    # 画像サイズの設定
    image_shape = (args.image_size, args.image_size, 3)

    # 学習済みモデルの読み込み
    if args.trained_model is None:
        if args.model_name == 'vgg16':
            load_pre_model = keras.applications.vgg16.VGG16
        elif args.model_name == 'xception':
            load_pre_model = keras.applications.xception.Xception
        elif args.model_name == 'inceptionv3':
            load_pre_model = keras.applications.inception_v3.InceptionV3
        elif args.model_name == 'inceptionresnetv2':
            load_pre_model = keras.applications.inception_resnet_v2.InceptionResNetV2
        elif args.model_name == 'densenet':
            load_pre_model = keras.applications.densenet.DenseNet121
        elif args.model_name == 'resnet50':
            load_pre_model = keras.applications.resnet50.ResNet50
        else:
            sys.stderr('invalid model_name: ', args.model_name)
        model = load_pre_model(input_shape=image_shape,
                               weights=None,
                               classes=args.num_classes,
                               include_top=True)
    else:
        tmp_model = keras.models.load_model(args.trained_model)

    model = tf.keras.models.clone_model(tmp_model)

    # # augumentationの設定
    # #   https://github.com/geifmany/cifar-vgg/blob/master/cifar100vgg.pyより拝借
    # if args.dont_augment:
    #     train_datagen = ImageDataGenerator(
    #         featurewise_center=False,  # set input mean to 0 over the dataset
    #         samplewise_center=False,  # set each sample mean to 0
    #         featurewise_std_normalization=False,  # divide inputs by std of the dataset
    #         samplewise_std_normalization=False,  # divide each input by its std
    #         zca_whitening=False,  # apply ZCA whitening
    #         rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)
    #         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
    #         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
    #         horizontal_flip=True,  # randomly flip images
    #         vertical_flip=False)  # randomly flip images
    # else:
    #     train_datagen = ImageDataGenerator()
    # test_datagen = ImageDataGenerator()
    #
    # # generatorの設定
    # train_generator = train_datagen.flow_from_directory(
    #     os.path.join(args.dataset_dir, 'train'),
    #     target_size=image_shape[:2],
    #     batch_size=args.batch_size,
    #     class_mode='categorical')
    # test_generator = test_datagen.flow_from_directory(
    #     os.path.join(args.dataset_dir, 'test'),
    #     target_size=image_shape[:2],
    #     batch_size=args.batch_size,
    #     class_mode='categorical')

    # generator setting
    train_generator = data_gen.ITrackerData(args.dataset_dir, 'train', (args.image_size, args.image_size), (25, 25),
                                            args.batch_size)
    test_generator = data_gen.ITrackerData(args.dataset_dir, 'test', (args.image_size, args.image_size), (25, 25),
                                           args.batch_size)

    # optimizerの指定
    opt = keras.optimizers.Adam()

    # compile
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])

    now = datetime.datetime.now()

    # callbacks
    cbks = [keras.callbacks.CSVLogger(
        os.path.join(args.save_dir, 'scratch_%s_%s.csv' % ("eye_tracking", now.strftime('%Y%m%d_%H%M%S'))))]

    # Fit the model on the batches generated by datagen.flow().
    history = model.fit_generator(
        generator=train_generator,
        steps_per_epoch=len(train_generator),
        epochs=args.epochs,
        verbose=1,
        validation_data=test_generator,
        validation_steps=len(test_generator),
        callbacks=cbks,
    )

    model.save('./model_scratch_{}.hdf5'.format(now.strftime('%Y%m%d_%H%M%S')))

    # save history
    # df_history = pd.DataFrame(history.history)
    # df_history.to_csv(os.path.join(args.save_dir, 'scratch_%s_%s.csv' % (args.model_name, args.learning_number)))


def getParser():
    parser = argparse.ArgumentParser()

    # N回回す実験用のアレ
    parser.add_argument('learning_number', help='for sequential experiment')

    # データセットのディレクトリ
    parser.add_argument('dataset_dir')

    # ログの保存先ディレクトリ
    parser.add_argument('save_dir')

    # クラス数
    parser.add_argument('--num_classes', type=int, default=100)

    # 学習データの画像数
    #   CIFAR10: 50000, CIFAR100: 50000
    parser.add_argument('--num_images_train', type=int, default=50000, help='CIFAR10: 50000, CIFAR100: 50000')

    # テストデータの画像数
    #   CIFAR10: 10000, CIFAR100: 10000
    parser.add_argument('--num_images_test', type=int, default=10000, help='CIFAR10: 10000, CIFAR100: 10000')

    # 画像サイズ
    parser.add_argument('--image_size', type=int, default=224)

    # バッチサイズ
    parser.add_argument('--batch_size', type=int, default=16)

    # エポック
    parser.add_argument('--epochs', type=int, default=60)

    # GPU並列
    parser.add_argument('--n_gpu', type=int, default=1)

    # CPU並列
    parser.add_argument('--n_thread', type=int, default=1)

    # CPU(スレッド)並列
    #   fit_generatorでスレッド並列するとデッドロックする臭い？
    #   https://github.com/keras-team/keras/issues/10340
    parser.add_argument('--use_multiprocessing', action='store_true')

    # 水増しの有無
    parser.add_argument('--dont_augment', action='store_false')

    # （テスト用）学習済みモデルの設定
    parser.add_argument('--trained_model', default=None)

    # 使う学習済みモデル
    parser.add_argument('--model_name', default='vgg16',
                        help='name of pre-trained network. this is disable by giving --trained_model')
    return parser


# 引数の読み込み
if __name__ == '__main__':
    parser = getParser()

    args = parser.parse_args()

    print('----PARSED ARGS----\n%s\n-----------------' % args)

    main(args)
